{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8093b6a5-2db6-4cde-8cc5-caf21f5cfa6c",
   "metadata": {},
   "source": [
    "# CSV files 1: reading a CSV file\n",
    "By the end of this lecture you will be able to:\n",
    "- set the column names when reading a CSV file\n",
    "- specify how to parse a CSV file\n",
    "- specify a dtype schema  when reading a CSV file\n",
    "- modify CPU and memory usage when reading a CSV file\n",
    "\n",
    "Warning: this is a long lecture as we go through the full CSV parsing process!\n",
    "\n",
    "## What is a CSV file?\n",
    "A CSV file is:\n",
    "- a text file that uses a comma (or other delimiter) to separate values\n",
    "- a file where data is ordered in rows rather than columns\n",
    "- a file where the only potential metadata is a header row of column names - no type information for each column is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f72df-7ddd-42d0-b330-9e077cd5b4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b40af-0594-4a5b-b008-aa78dce4e101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88371f6e-5b61-4268-a1fe-b53847610a45",
   "metadata": {},
   "source": [
    "We read this CSV file as we have read it many times before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d6141-fd94-4476-9e51-3bfb0af5be8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pl.read_csv(csv_file)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30205e-655e-42e1-a40e-5e172885258d",
   "metadata": {},
   "source": [
    "## CSV parsers\n",
    "\n",
    "CSV files are text and so must be parsed to:\n",
    "1. get the column names\n",
    "2. split each row into columns\n",
    "3. infer the dtype of each column\n",
    "\n",
    "## Header and column names\n",
    "By default Polars takes the first row of a CSV as the header to set the column names.\n",
    "\n",
    "### No header\n",
    "If the first row is not a header we can set `has_header = False` and the column names are `column_1` etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a494296-b900-4637-a3b4-179bb77d3c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(\n",
    "        csv_file, \n",
    "        has_header=False\n",
    "    )\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed117b-5632-420c-b02d-e1041b63ee2c",
   "metadata": {},
   "source": [
    "### Rename columns\n",
    "We can rename columns immediately after the CSV is parsed with `new_columns`.\n",
    "\n",
    "In this example we rename the first column in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c7fbf-92b5-4fd4-b89c-e59c77f70249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(\n",
    "        csv_file,\n",
    "        new_columns=['passengerid']\n",
    "    )\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e025d3-d604-449d-9647-96f345614a4f",
   "metadata": {},
   "source": [
    "### Skip rows after the header\n",
    "We skip rows after the header is parsed with `skip_rows_after_header`. In this example it drops the first row of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe3ec0-f326-45f7-b051-7bd4afb69855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(\n",
    "        csv_file,\n",
    "        skip_rows_after_header=1\n",
    "    )\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914822c-cf11-4175-8443-d652f4a34653",
   "metadata": {},
   "source": [
    "### Skip rows to the header\n",
    "\n",
    "If the header is on line `N` of the CSV we can set `skip_rows = N - 1`.\n",
    "\n",
    "In this example we set line 2 of the CSV as the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6acfc2-47c8-4ee3-ae32-e5ec18b473b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(\n",
    "        csv_file,\n",
    "        skip_rows=1\n",
    "    )\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e9e136-9aa0-401a-a430-51d656e0bdb4",
   "metadata": {},
   "source": [
    "If header names are duplicated (as with columns 7 and 8 of this example) Polars adds `_duplicated_0` to the column name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41acf96e-1651-4057-a3da-5585c5cfcb70",
   "metadata": {},
   "source": [
    "## Parsing CSVs\n",
    "In the following examples we simulate CSV files with Python strings like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f6db93-a5fd-4347-a6e5-c6fdad2450ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B,C\\n0,1,2\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8755e2c3-8620-4237-9586-0ad9d5395978",
   "metadata": {},
   "source": [
    "- The newline `\\n` character shows the line breaks in the simulated CSV file\n",
    "- The `b` before the start of the string converts the string to bytes so that it can be passed to `pl.read_csv` (otherwise if we pass a `str` Polars thinks it is a file path to a CSV and raises an `Exception`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54980db4-0801-4fc4-a133-7d5397278099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.read_csv(CSV_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3400c1e-5ada-49a4-be8f-03e2ea5783d0",
   "metadata": {},
   "source": [
    "### Delimiter\n",
    "Polars assumes the delimiter is a `,`, but this can be changed with the `sep` argument.\n",
    "\n",
    "In this example we have a CSV with tab (`\\t`) separated data rather than comma-separated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11cbf0c-2bf6-40f7-addc-c85d5f35201a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab_CSV_string = b\"A\\tB\\tC\\n0\\t1\\t2\\n\"\n",
    "\n",
    "(\n",
    "    pl.read_csv(\n",
    "        tab_CSV_string,\n",
    "        separator=\"\\t\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ad32c-0943-4cfc-8672-c0acad321f8d",
   "metadata": {},
   "source": [
    "### Comment lines\n",
    "\n",
    "Comment lines that start with a certain character in the CSV are ignored by setting the `comment_prefix`. Here we have a comment row after the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52716f-a72b-42fb-bfb8-52fe2baafda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_CSV_string = b\"a,b,c\\n#Comment\\n0,1,2\\n\"\n",
    "(\n",
    "    pl.read_csv(\n",
    "        comment_CSV_string,\n",
    "        comment_prefix=\"#\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889dc84-b01b-40ad-8d33-cdbf8acc413d",
   "metadata": {},
   "source": [
    "### Quotes\n",
    "Quotes in the CSV are indicated with the `quote_char`. \n",
    "\n",
    "In this example we have quotes because a text entry contains a comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78a745-22ed-4af0-a908-01e5bd9a5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_CSV_string = b'name,age\\n\"Armstrong,Neil\",39\\n'\n",
    "(\n",
    "    pl.read_csv(\n",
    "        quote_CSV_string,\n",
    "        quote_char='\"'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e80c70a-4005-4da7-aa96-0f63befbe97d",
   "metadata": {},
   "source": [
    "### Choosing columns\n",
    "We can restrict which columns are in the `DataFrame` with the `columns` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fbd3a-1db3-444f-993d-1a4cf2bfad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B,C\\n0,1,2\\n\"\n",
    "(\n",
    "    pl.read_csv(\n",
    "        CSV_string,\n",
    "        columns=[\"A\",\"C\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02fc44-e9da-415b-9dce-2640353f1948",
   "metadata": {},
   "source": [
    "We can also do this in lazy mode with the projection pushdown optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404c4b4-9539-43a7-8356-b80468a6f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(CSV_string)\n",
    "    .select(\"A\",\"C\")\n",
    "    .head(2)\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce1d89a-e981-401b-8e7b-d2f5f4b900ea",
   "metadata": {},
   "source": [
    "## Inferring the dtypes\n",
    "Unlike the Parquet files we meet later, CSVs do not store the dtype of each column. \n",
    "\n",
    "Therefore Polars infers the dtype of each column in the CSV. To do this Polars:\n",
    "- reads the first 100 lines\n",
    "- if a dtype can be inferred it sets the dtype for that column\n",
    "- if a consistent dtype cannot be inferred then a `ComputeError` exception is raised\n",
    "\n",
    "### Number of rows to infer the dtypes\n",
    "We can adjust the number of lines used for type inference.\n",
    "\n",
    "In the Titanic CSV the `Age` column starts off with 57 integers before there is a decimal value in line 58.\n",
    "\n",
    "If we try to set `infer_schema_length` lower than 58  Polars raises a `ComputeError` because it infers an integer dtype and then encounters a float on line 58 (you can check this by reducing the `infer_schema_length` value here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2709b3-e29f-4b29-af29-fe77801239aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(\n",
    "        csv_file,\n",
    "        infer_schema_length=58\n",
    "    )\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66219cc2-cada-4b3a-8a84-15d6ccca55e1",
   "metadata": {},
   "source": [
    "If you are getting errors from parsing the schema it is worth increasing `infer_schema_length` to see if that resolves the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da34e810-0491-49d7-bd9e-1b8fad9bba6f",
   "metadata": {},
   "source": [
    "### Setting the schema\n",
    "We can also define the full schema explicitly with a `dict` when reading the CSV. With the `schema` argument set Polars does not do the schema inferrence step described above.\n",
    "\n",
    "In this example we read in integers and floats as 32-bit dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f9738-cde0-4294-95e5-9b69e51b0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(\n",
    "        csv_file,\n",
    "        schema={\n",
    "            \"PassengerId\": pl.Int32,\n",
    "            \"Survived\": pl.Int32,\n",
    "            \"Pclass\": pl.Int32,\n",
    "            \"Name\": pl.String,\n",
    "            \"Sex\": pl.String,\n",
    "            \"Age\": pl.Float32,\n",
    "            \"SibSp\": pl.Int32,\n",
    "            \"Parch\": pl.Int32,\n",
    "            \"Ticket\": pl.String,\n",
    "            \"Fare\": pl.Float32,\n",
    "            \"Cabin\": pl.String,\n",
    "            \"Embarked\": pl.String,\n",
    "        },\n",
    "    )\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9997b-9650-4732-ae08-0a78a122cceb",
   "metadata": {},
   "source": [
    "However, with `schema` we need to pass the schema for all columns, which can be tedious.\n",
    "\n",
    "We can instead use `schema_overrides` to override the inferred schema for specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07600259-d602-47cd-a9a6-c8ee9b249fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(\n",
    "        csv_file,\n",
    "        schema_overrides={\n",
    "            \"PassengerId\": pl.Int32,\n",
    "            \"Survived\": pl.Int32,\n",
    "            \"Pclass\": pl.Int32,\n",
    "        },\n",
    "    )\n",
    "    .head(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994efd9f-47fa-4948-b071-8271e8b27b56",
   "metadata": {},
   "source": [
    "## Handling mixed types and exceptions\n",
    "In this example we have a CSV file that will raise an exception as the values in the first column are:\n",
    "- `1.0` which looks like a float and \n",
    "- `a` which is a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005dd518-9232-41dc-aadc-3ab1ba27b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_CSV_string = b\"A,B\\n1.0,1\\na,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d2133-f50d-4218-a23b-b22e6739f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_csv(mixed_CSV_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e849a0d-2f87-4b3d-9bdd-e197e4679f60",
   "metadata": {},
   "source": [
    "In this case Polars casts the column to string dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4337334-b2dd-48b9-bbd5-80129770e84f",
   "metadata": {},
   "source": [
    "### Ignore errors\n",
    "We can also tell Polars to ignore errors in which case values that cannot be cast to the schema for that column are returned as `null`.\n",
    "\n",
    "In this case we try to make column `A` boolean but have `True` in the first row and `0` in the second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19d8f5-4934-4bdf-884e-0c57241b76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B\\nTrue,1\\n0,1\\n\"\n",
    "\n",
    "(\n",
    "    pl.read_csv(\n",
    "        CSV_string,\n",
    "        schema_overrides={'A':pl.Boolean},\n",
    "        ignore_errors=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae063ad-4dd6-4f86-aabf-791d524a417d",
   "metadata": {},
   "source": [
    "The `DataFrame` has a `null` where the `0` in the second row was."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e78f2-6376-431f-b839-86c225767664",
   "metadata": {},
   "source": [
    "## Set values to `null`\n",
    "We might know that there are values in a column that are incorrect.\n",
    "\n",
    "In this case the CSV has `NaN` in column `B.` We set this to `null` with `null_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee02a9-0495-427e-ac0b-03bc6ae2c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B\\nTrue,1\\nFalse,NaN\\n\"\n",
    "\n",
    "(\n",
    "    pl.read_csv(\n",
    "        CSV_string,\n",
    "        null_values=\"NaN\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8d523-d7d2-4ede-8a24-b9329f4d2794",
   "metadata": {},
   "source": [
    "We can also pass a list of strings to `null_values` or specify different values to set as `null` for different columns with a `dict`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47330eed-bc10-4e1a-ba02-d332a2fdeb5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81cf048-9191-40e5-83cc-1e091c22f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B\\nTrue,1\\nFalse,NaN\\n\"\n",
    "\n",
    "(\n",
    "    pl.read_csv(\n",
    "        CSV_string,\n",
    "        null_values={\"B\":\"NaN\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c7ab8-70f4-45d9-b6bd-8835095b6503",
   "metadata": {},
   "source": [
    "## Performance of CSV parsing\n",
    "### Number of threads\n",
    "The CSV parser in Polars is multithreaded and uses the same number of threads as there are cores on your computer.\n",
    "\n",
    "We can vary the number of threads with the `n_threads` argument. We can use fewer threads to reduce CPU usage or more threads to (potentially) reduce read time.\n",
    "\n",
    "In experiments on my computer (8 cores) with different datasets compared to the default:\n",
    "- reducing `n_threads` to 1 increases time taken by 3x\n",
    "- reducing `n_threads` to 3-4 increases time taken by 30%\n",
    "- increasing `n_threads` to 40 reduces time taken by 30% on some datasets but makes no difference on others\n",
    "\n",
    "In general setting `n_threads` is mainly useful if you want to slow down CSV parsing to avoid impacting other processes on the machine.\n",
    "\n",
    "### Memory usage\n",
    "We can potentially reduce memory usage when reading a large CSV with `low_memory = True`. When reading a large CSV Polars reads the CSV into separate chunks in memory before combining the chunks into a `DataFrame` that is a single chunk in memory.\n",
    "\n",
    "With `low_memory = True` Polars uses a slower non-parallel method of combining the chunks into a `DataFrame` that is a single chunk in memory.\n",
    "\n",
    "We can also reduce the size of each batch read by the parallel CSV reader with `batch_size`. This may reduce memory pressure where each line is very long or has variable length (e.g. when there is text on each line with variable length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1005b-e1b2-40b6-a16e-0cf3691f777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(\n",
    "        csv_file,\n",
    "        low_memory=True,\n",
    "        batch_size=1e5\n",
    "    )\n",
    ")               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4513841-45a2-4384-a18a-0a1d8ecf80d4",
   "metadata": {},
   "source": [
    "Be aware that these settings only make a marginal difference to the amount of memory used. If you are trying to work with a CSV that is just too big for your machine then it is best to use streaming mode as explored later in this Section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a67e7d-dd2f-4be3-96f9-b5149c9f4be7",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "In the exercises you will develop your understanding of:\n",
    "- setting the column names of a CSV\n",
    "- parsing a CSV\n",
    "- setting the dtypes\n",
    "- modifying the number of threads\n",
    "\n",
    "### Exercise 1\n",
    "In this exercise we want to parse the CSV strings to produce a `DataFrame` equal to the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cdf998-aba8-4d7b-9da0-b22c5a2940a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pl.DataFrame({\"a\":[1,2],\"b\":[3,4],\"c\":[5,6]})\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc206a1-7942-41c3-a102-1b474c9befe2",
   "metadata": {},
   "source": [
    "Parse the CSV strings in the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b84975-a5eb-4769-84c7-b6c995cc3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"Data passed quality control 2020-01-01\\na,b,c\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1d0ce-c504-49bd-8422-ba3ee14715a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "CSV_string = b\"A,B,C\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277becfd-180b-43e1-becc-be054ec3a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitespace delimiter\n",
    "CSV_string = b\"a b c\\n1 3 5\\n2 4 6\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23cbcc6-27ab-4237-b7e2-654e3592a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment line\n",
    "CSV_string = b\"a,b,c\\n#Data passed quality control 2020-01-01\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d7c7bc-ae67-4687-8c3a-b04edaca5d6b",
   "metadata": {},
   "source": [
    "This time parse the CSV to produce a `DataFrame` with all columns as 64-bit floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7707d42-0fa0-41eb-998d-a8e7f251e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"a,b,c\\n#Data passed quality control 2020-01-01\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9ec04-5c98-4b5f-afd8-1a9d2392581c",
   "metadata": {},
   "source": [
    "Find missing data in the CSV and replace with `null`. Ensure columns are not cast to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ae520-43ee-4c09-ac19-1eb36d6226f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_string = b\"a,b,c\\n1,3,5\\nNA,4,na\\n\"\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52c4a3-bd2e-4f6a-a410-07cf3264db2b",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Parse the NYC taxi CSV with:\n",
    "- the default number of threads,\n",
    "- one thread and\n",
    "- 40 threads\n",
    "to see if it affects performance.\n",
    "\n",
    "(This dataset is too small to see any differences - but try it with your own datasets to see if changing the number of threads affects performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec8a2a-5c9e-4346-a038-f9ff5c4d4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyccsv_file = \"../data/nyc_trip_data_1k.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d5ce6-0c02-459c-8ced-50401965bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "pl.read_csv(<blank>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2db91-088f-47ef-a4ca-07b462f4958f",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Solution to exercise 1\n",
    "In this exercise we want to parse the CSV strings to produce a `DataFrame` equal to the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79cf4bd-037b-4af9-8a03-6bd8803d5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pl.DataFrame({\"a\":[1,2],\"b\":[3,4],\"c\":[5,6]})\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8763d8c-5691-4402-a7d3-90f207fa27c8",
   "metadata": {},
   "source": [
    "Parse the CSV strings in the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b01f3-7369-47b5-9716-820bc6e3a108",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"Data passed quality control 2020-01-01\\na,b,c\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(CSV_string,skip_rows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3721b-7f86-42bd-9dae-ba401fc4af29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"A,B,C\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(CSV_string,new_columns=[\"a\",\"b\",\"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f1327-0020-4774-b74b-c2dda04bc37c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"a b c\\n1 3 5\\n2 4 6\\n\"\n",
    "pl.read_csv(CSV_string,separator=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc2852-b77c-45a3-935d-ea922949167c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"a,b,c\\n#Data passed quality control 2020-01-01\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(CSV_string,comment_prefix=\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240f42e-977f-4457-b2ac-e99743f44198",
   "metadata": {},
   "source": [
    "This time parse the CSV with all columns as 64-bit floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc24441-ba07-49ea-97db-b4050845216a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"a,b,c\\n#Data passed quality control 2020-01-01\\n1,3,5\\n2,4,6\\n\"\n",
    "pl.read_csv(CSV_string,comment_prefix=\"#\",schema_overrides={\"a\":pl.Float64,\"b\":pl.Float64,\"c\":pl.Float64})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3908d1-2cc5-4703-be94-7e24af7ef9bd",
   "metadata": {},
   "source": [
    "Find missing data and replace with `null`. Ensure columns are not cast to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9ad78-de70-4d8d-b21f-cfc56137cdc2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_string = b\"a,b,c\\n1,3,5\\nNA,4,na\\n\"\n",
    "pl.read_csv(CSV_string,null_values={\"a\":\"NA\",\"c\":\"na\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16e14d-67cb-4bbc-8458-96a723ce4c4b",
   "metadata": {},
   "source": [
    "## Solution to exercise 2\n",
    "Parse the NYC taxi CSV with:\n",
    "- the default number of threads\n",
    "- one thread\n",
    "- 40 threads\n",
    "to see if it affects performance.\n",
    "\n",
    "Then try it with your own datasets to see if it affects performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1af91-f87f-4584-ac38-834364735968",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyccsv_file = \"../data/nyc_trip_data_1k.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd30356c-6ecc-4b01-904c-e1875151587c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n1\n",
    "pl.read_csv(nyccsv_file,n_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835d011-feb8-4d74-93cd-7f8db7936530",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n1\n",
    "pl.read_csv(nyccsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3439294d-23bd-4bee-a3d0-41c43394c899",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n1\n",
    "pl.read_csv(nyccsv_file,n_threads=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
